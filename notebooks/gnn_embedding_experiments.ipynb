{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sanketh/DANI/GraphMatching/\")\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! WARNING: COULD NOT IMPORT rpy2, check R_HOME path exists: C:\\Program Files\\R\\R-4.3.2 !!!\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import itertools\n",
    "from common.parallel_computation import tqdm_joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "import pickle\n",
    "from livelossplot import PlotLosses\n",
    "import time\n",
    "from common.logger import TimeLogging\n",
    "from subgraph_matching_via_nn.data.data_loaders import load_graph\n",
    "from powerful_gnns.models.graphcnn import GraphCNN\n",
    "from powerful_gnns.util import separate_data\n",
    "from powerful_gnns.classifier_training import train, test\n",
    "from common.EmbeddingCalculationsService import pairwise_l2_distance, show_distance_matrix, \\\n",
    "    calculate_energy_based_hidden_rep\n",
    "from subgraph_matching_via_nn.training.PairSampleInfo import Pair_Sample_Info\n",
    "from subgraph_matching_via_nn.data.annotated_graph import AnnotatedGraph\n",
    "from subgraph_matching_via_nn.training.trainer.S2VGraphEmbeddingSimilarityMetricTrainer import \\\n",
    "    S2VGraphEmbeddingSimilarityMetricTrainer\n",
    "from common.graph_data_experiments_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes_device_ids = [0, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "goal_subcircuit_name = 'alu'\n",
    "DATA_PATH = 'C:/Users/kogan/OneDrive/Desktop/Research/AMIT/GraphMatching/subgraph_matching_via_nn/data/subcircuits/'\n",
    "DATA_PATH = '../subgraph_matching_via_nn/data/subcircuits/'\n",
    "\n",
    "desktop = pathlib.Path(DATA_PATH)\n",
    "subgraphs = []\n",
    "labels = []\n",
    "for circuit_dir in desktop.iterdir():\n",
    "    if circuit_dir.is_dir():\n",
    "        for subcircuit_file in circuit_dir.iterdir():\n",
    "            if subcircuit_file.is_file():\n",
    "                file_name = subcircuit_file.name\n",
    "                if file_name == 'full_graph.p':\n",
    "                    file_rel_path = f\"{os.sep}{file_name}\"\n",
    "                    loader_params = {\n",
    "                     'data_path' : str(circuit_dir),\n",
    "                     'g_full_path': file_rel_path,\n",
    "                     'g_sub_path': file_rel_path}\n",
    "\n",
    "                    sub_graph = \\\n",
    "                        load_graph(type='subcircuit',\n",
    "                                   loader_params=loader_params)\n",
    "\n",
    "                    if goal_subcircuit_name in circuit_dir.name:\n",
    "                        labels.append(1)\n",
    "                    else:\n",
    "                        # continue #TODO?\n",
    "                        labels.append(0)\n",
    "                    subgraphs.append(sub_graph)\n",
    "\n",
    "labels = np.array(labels, dtype='float32')\n",
    "N = len(subgraphs)\n",
    "N_training = int(2 / 3 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subgraphs = []\n",
    "labels = []\n",
    "\n",
    "subgraphs_for_classification = []\n",
    "\n",
    "circuit_base_dir = 'C:\\\\Users\\\\kogan\\\\OneDrive\\\\Desktop\\\\Research\\\\AMIT\\\\GraphMatching\\\\subgraph_matching_via_nn\\\\data\\\\subcircuits\\\\'\n",
    "circuit_base_dir = '/home/sanketh/DANI/GraphMatching/subgraph_matching_via_nn/data/subcircuits/'\n",
    "CIRCUIT_DUPLICATES_AMOUNT = 5\n",
    "REFERENCE_GRAPH_ORIGINAL_LABEL = 1\n",
    "REFERENCE_GRAPH_ORIGINAL_INDEX = 0\n",
    "\n",
    "for circuit_file_name in ['adder_4', 'alu_4', 'alu_8', 'alu_16', 'alu_32', 'mul_4_4', 'mul_4_8', 'mul_8_8', 'mul_16_16', 'mul_16_32']:\n",
    "    file_rel_path = 'full_graph.p'\n",
    "    circuit_dir = f\"{circuit_base_dir}{circuit_file_name}{os.sep}\"\n",
    "    loader_params = {\n",
    "     'data_path' : str(circuit_dir),\n",
    "     'g_full_path': file_rel_path,\n",
    "     'g_sub_path': file_rel_path}\n",
    "\n",
    "    sub_graph = \\\n",
    "        load_graph(type='subcircuit',\n",
    "                   loader_params=loader_params)\n",
    "    subgraphs.append(sub_graph)\n",
    "    for i in range(CIRCUIT_DUPLICATES_AMOUNT):\n",
    "        subgraphs_for_classification.append(sub_graph)\n",
    "        labels.append(0)\n",
    "for i in range(CIRCUIT_DUPLICATES_AMOUNT):\n",
    "    labels[REFERENCE_GRAPH_ORIGINAL_INDEX * CIRCUIT_DUPLICATES_AMOUNT + i] = REFERENCE_GRAPH_ORIGINAL_LABEL\n",
    "\n",
    "zipped_graphs_and_labels = list(zip(subgraphs_for_classification, labels))\n",
    "random.shuffle(zipped_graphs_and_labels)\n",
    "unzipped_graphs_and_labels = list(zip(*zipped_graphs_and_labels))\n",
    "subgraphs_for_classification = unzipped_graphs_and_labels[0]\n",
    "labels = unzipped_graphs_and_labels[1]\n",
    "\n",
    "N = len(subgraphs_for_classification)\n",
    "N_training = int(2 / 3 * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Transform graphs into S2VGraph-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes: 2\n",
      "# maximum node tag: 48\n",
      "# data: 50\n"
     ]
    }
   ],
   "source": [
    "graphs, num_classes = transform_into_s2vgraphs(subgraphs_for_classification, labels, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Setup model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#set up seeds and gpu device\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "##k-fold cross validation. Conduct an experiment on the fold specified by args.fold_idx.\n",
    "# train_graphs, test_graphs = separate_data(graphs, seed=0, fold_idx=0, n_splits=1)\n",
    "# train_graphs = graphs[:4]\n",
    "# test_graphs = graphs[4:]\n",
    "train_graphs = graphs[:N_training]\n",
    "test_graphs = graphs[N_training:]\n",
    "\n",
    "model = GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=train_graphs[0].node_features.shape[1], hidden_dim=64, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "liveloss = PlotLosses(mode='notebook')\n",
    "\n",
    "filename = \"\"\n",
    "epochs = 20\n",
    "k_update_plot = 1\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = train(iters_per_epoch=50, batch_size=len(train_graphs), model=model, device=device, train_graphs=train_graphs, optimizer=optimizer, epoch=epoch)\n",
    "    acc_train, acc_test = test(model, device, train_graphs, test_graphs, epoch)\n",
    "\n",
    "    if not filename == \"\":\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"%f %f %f\" % (avg_loss, acc_train, acc_test))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(model.eps)\n",
    "\n",
    "    if epoch % k_update_plot == 0:\n",
    "        liveloss.update({'train error': avg_loss.item()})\n",
    "        liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Show predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(train_graphs).max(1, keepdim=True)[1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred = model(test_graphs).max(1, keepdim=True)[1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "show all distances matrix (margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes: 2\n",
      "# maximum node tag: 48\n",
      "# data: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanketh/DANI/GraphMatching/powerful_gnns/models/graphcnn.py:150: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)\n",
      "  graph_pool = torch.sparse.FloatTensor(idx, elem, torch.Size([len(batch_graph), start_idx[-1]]))\n"
     ]
    }
   ],
   "source": [
    "# keep only one instance of each graph\n",
    "graphs, num_classes = transform_into_s2vgraphs(subgraphs, labels, device)\n",
    "\n",
    "all_embeddings = model.get_embedding(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_dists = pairwise_l2_distance(all_embeddings)[REFERENCE_GRAPH_ORIGINAL_INDEX].reshape(-1, 1)\n",
    "\n",
    "rounding_constant = 10 ** 3\n",
    "cos_dists = (torch.round(calculate_energy_based_hidden_rep(all_embeddings, threshold=-1) * rounding_constant) / rounding_constant)[REFERENCE_GRAPH_ORIGINAL_INDEX].reshape(-1, 1)\n",
    "\n",
    "show_distance_matrix(l2_dists, \"l2-distances\")\n",
    "show_distance_matrix(cos_dists, \"cosine-distances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "what is the smallest margin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.02391052246094\n",
      "0.007000000216066837\n"
     ]
    }
   ],
   "source": [
    "print(get_min_non_diagonal_entry(l2_dists, device, REFERENCE_GRAPH_ORIGINAL_INDEX))\n",
    "print(get_min_non_diagonal_entry(cos_dists, device, REFERENCE_GRAPH_ORIGINAL_INDEX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Contrastive loss training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Assemble graph pairs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_samples_list = []\n",
    "reference_subgraph = subgraphs[REFERENCE_GRAPH_ORIGINAL_INDEX]\n",
    "negative_examples_subgraphs = subgraphs[:REFERENCE_GRAPH_ORIGINAL_INDEX] + subgraphs[REFERENCE_GRAPH_ORIGINAL_INDEX+1:]\n",
    "\n",
    "for subgraph in subgraphs:\n",
    "    if subgraph == reference_subgraph:\n",
    "        is_negative_example = False\n",
    "    else:\n",
    "        is_negative_example = True\n",
    "\n",
    "    G1_annotated = AnnotatedGraph(subgraph.G)\n",
    "    G2_annotated = AnnotatedGraph(reference_subgraph.G)\n",
    "    train_samples_list.append(Pair_Sample_Info(\n",
    "        subgraph=G1_annotated,\n",
    "        masked_graph=G2_annotated,\n",
    "        is_negative_sample=torch.tensor(is_negative_example)))\n",
    "\n",
    "val_samples_list = train_samples_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Define GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input dim matches the node mask (w) shape\n",
    "input_dim = S2VGraphEmbeddingSimilarityMetricTrainer.get_model_expected_input_dim(train_samples_list[0])\n",
    "model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=input_dim, hidden_dim=64, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Define graph metric to train, and the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "solver_params = {\n",
    "    \"device\": device,\n",
    "    \"lr\": 1e-3, \"weight_decay\": 1e-3,\n",
    "    \"max_epochs\": 50,\n",
    "    \"cycle_patience\": 5, \"step_size_up\": 10, \"step_size_down\": 10,\n",
    "    \"loss_convergence_threshold\": None,\n",
    "    \"train_loss_convergence_threshold\": 1e-3,\n",
    "    \"successive_convergence_min_iterations_amount\": 5,\n",
    "    \"margin_loss_margin_value\": 5,\n",
    "    \"max_grad_norm\": 0.1,\n",
    "    \"k_update_plot\": 1,\n",
    "    \"train_monitoring_epochs_pace\": 5,\n",
    "    \"batch_size\": len(subgraphs),\n",
    "    \"num_workers\": 0,\n",
    "    \"is_use_model_compliation\": False, #Only supported for Pytorch > 2.0\n",
    "    \"model_checkpoint_epochs_pace\": 10,\n",
    "}\n",
    "\n",
    "problem_params = {\"input_dim\": input_dim}\n",
    "\n",
    "trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# show_distances_heatmap(generate_s2v_graphs([graph.g for graph in graphs], device), model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train(processes_device_ids=['cpu'], use_existing_data_loaders=False, train_samples_list=train_samples_list, val_samples_list=val_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_distances_heatmap(generate_s2v_graphs([graph.g for graph in graphs], device), model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Add ged=1 examples as positive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate subgraphs for which ged(subgraph, reference_subgraph)==1\n",
    "perturbed_graphs = list(generate_perturbed_graphs(reference_subgraph.G_sub))\n",
    "for perturbed_graph in perturbed_graphs:\n",
    "    is_negative_example = False\n",
    "\n",
    "    G1_annotated = AnnotatedGraph(perturbed_graph)\n",
    "    G2_annotated = AnnotatedGraph(reference_subgraph.G)\n",
    "    train_samples_list.append(Pair_Sample_Info(\n",
    "        subgraph=G1_annotated,\n",
    "        masked_graph=G2_annotated,\n",
    "        is_negative_sample=torch.tensor(is_negative_example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(train_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_samples_list = train_samples_list\n",
    "model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=input_dim, hidden_dim=64, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "solver_params[\"batch_size\"] = len(train_samples_list)\n",
    "\n",
    "trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params)\n",
    "\n",
    "trainer.train(processes_device_ids=['cpu'], use_existing_data_loaders=False, train_samples_list=train_samples_list, val_samples_list=val_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_s2v_graphs = generate_s2v_graphs([subgraph.G for subgraph in subgraphs] + perturbed_graphs, device)\n",
    "# show_distances_heatmap(all_s2v_graphs, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_distances_heatmap(all_s2v_graphs[:len(subgraphs)], model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reference_s2v_graph = all_s2v_graphs[REFERENCE_GRAPH_ORIGINAL_INDEX]\n",
    "reference_graph_with_positive_examples = [reference_s2v_graph] + all_s2v_graphs[len(subgraphs):]\n",
    "reference_graph_with_negative_examples = [all_s2v_graphs[i] for i in range(len(all_s2v_graphs[:len(subgraphs)]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_distances_heatmap(reference_graph_with_positive_examples, model, device, show_min_off_diagonal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_distances_heatmap(reference_graph_with_negative_examples, model, device, show_min_off_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = graph_metric_nn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positive_distances = []\n",
    "for positive_example_second_graph in reference_graph_with_positive_examples:\n",
    "    distance = graph_metric_nn.forward([(reference_s2v_graph, positive_example_second_graph)]).item()\n",
    "    positive_distances.append(distance)\n",
    "    if distance > solver_params['margin_loss_margin_value']:\n",
    "        print(f\"positive loss term not zero, as distance for this positive example pair is {distance}\")\n",
    "\n",
    "negative_distances = []\n",
    "for negative_example_second_graph in reference_graph_with_negative_examples:\n",
    "    if negative_example_second_graph == reference_s2v_graph:\n",
    "        continue #ignore the same graph with itself\n",
    "    distance = graph_metric_nn.forward([(reference_s2v_graph, negative_example_second_graph)]).item()\n",
    "    negative_distances.append(distance)\n",
    "    if distance < solver_params['margin_loss_margin_value']:\n",
    "        print(f\"negative loss term not zero, as distance for this negative example pair is {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max(positive_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min(negative_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "k-subgraphs experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "K = 11\n",
    "full_graph = reference_subgraph.G\n",
    "\n",
    "subgraphs_iterator = itertools.combinations(full_graph, K)\n",
    "k_subgraphs = [full_graph.subgraph(s) for s in subgraphs_iterator]\n",
    "k_subgraph_annotated_graphs = [AnnotatedGraph(g, label=i) for i, g in enumerate(k_subgraphs)]\n",
    "\n",
    "train_samples_list = []\n",
    "isomorphic_pairs = []\n",
    "train_sample_indices_tuple_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for subgraph_counter1, SG_annotated_1 in enumerate(k_subgraph_annotated_graphs):\n",
    "    for subgraph_counter2 in range(subgraph_counter1+1, len(k_subgraph_annotated_graphs)):\n",
    "        SG_annotated_2 = k_subgraph_annotated_graphs[subgraph_counter2]\n",
    "        train_samples_list.append(compare_graphs_and_generate_pair_example(SG_annotated_1, SG_annotated_2, isomorphic_pairs))\n",
    "        train_sample_indices_tuple_list.append((subgraph_counter1, subgraph_counter2))\n",
    "        # if train_samples_list[-1].is_negative_sample == False:\n",
    "        #     print(f\"{subgraph_counter1} vs {subgraph_counter2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "used_train_samples_list = train_samples_list[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=input_dim, hidden_dim=128, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "solver_params[\"batch_size\"] = 512\n",
    "solver_params[\"k_update_plot\"] = 1\n",
    "solver_params[\"lr\"] = 1e-1\n",
    "solver_params[\"max_epochs\"] = 50\n",
    "trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=None)\n",
    "\n",
    "trainer.train(processes_device_ids=[0], use_existing_data_loaders=False, train_samples_list=used_train_samples_list, val_samples_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=\"./mp/1704585490.4369323/best_model_state_dict.pt\")\n",
    "_ = graph_metric_nn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_positive_distances, train_negative_distances = get_examples_distances(trainer, graph_metric_nn, used_train_samples_list)\n",
    "plot_histogram(train_positive_distances, \"positive pair distances\", min_range=0, max_range=20)\n",
    "plot_histogram(train_negative_distances, \"negative pair distances\", min_range=0, max_range=20)\n",
    "calc_margin_loss(torch.tensor(train_positive_distances+train_negative_distances), torch.cat((torch.ones(len(train_positive_distances)), torch.zeros(len(train_negative_distances)))), margin = solver_params['margin_loss_margin_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ged_pairs_dump_base_path = f\".{os.sep}ged_pairs\n",
    "\n",
    "# loaded_ged_examples = []\n",
    "# for i, doc_path in enumerate(pathlib.Path(ged_pairs_dump_base_path).rglob(\"*.p*\")):\n",
    "#     k_subgraph_ged_pairs_list = pickle.load(open(doc_path, 'rb'))\n",
    "#     loaded_ged_examples += k_subgraph_ged_pairs_list\n",
    "#     print(i)\n",
    "\n",
    "# if not os.path.exists(ged_pairs_dump_base_path):\n",
    "#     os.makedirs(ged_pairs_dump_base_path)\n",
    "#\n",
    "# # k_subgraph_to_perturbed_graphs_map = {}\n",
    "# def generate_ged_paris(subgraph_counter1):\n",
    "#     train_samples_list = []\n",
    "#     SG1 = k_subgraph_annotated_graphs[subgraph_counter1]\n",
    "#     ged1_perturbed_graphs = list(generate_perturbed_graphs(SG1.g))\n",
    "#     for ged1_perturbed_graph in ged1_perturbed_graphs:\n",
    "#         # positive example\n",
    "#         train_samples_list.append(generate_pair_example(SG1, AnnotatedGraph(ged1_perturbed_graph), is_negative_example = False))\n",
    "#\n",
    "#         ged2_perturbed_graphs = list(generate_perturbed_graphs(ged1_perturbed_graph))\n",
    "#         for ged2_perturbed_graph in ged2_perturbed_graphs:\n",
    "#             # could be positive or negative example\n",
    "#             train_samples_list.append(compare_graphs_and_generate_pair_example(k_subgraph_annotated_graphs[subgraph_counter1], AnnotatedGraph(ged2_perturbed_graph)))\n",
    "#\n",
    "#     path = os.path.join(ged_pairs_dump_base_path, f\"subgraph_{subgraph_counter1}.p\")\n",
    "#     with open(path, 'wb') as f:\n",
    "#         pickle.dump(train_samples_list, f)\n",
    "#     return train_samples_list\n",
    "#\n",
    "# total_tasks = len(k_subgraphs)\n",
    "# with tqdm_joblib(tqdm(desc=\"My calculation\", total=total_tasks)) as progress_bar:\n",
    "#     #Parallel(n_jobs=16)(delayed(long_task)() for i in range(10))\n",
    "#\n",
    "#     ged_examples = Parallel(n_jobs=int(cpu_count()), prefer='processes')(\n",
    "#         delayed(generate_ged_paris)(subgraph_counter1=subgraph_counter1)\n",
    "#         for subgraph_counter1 in range(total_tasks)\n",
    "#     )\n",
    "#\n",
    "# # generate subgraphs for which GED==1\n",
    "# for subgraph_counter1, SG1 in enumerate(k_subgraphs):\n",
    "#     print(subgraph_counter1)\n",
    "#     ged1_perturbed_graphs = list(generate_perturbed_graphs(SG1))\n",
    "#     for ged1_perturbed_graph in ged1_perturbed_graphs:\n",
    "#         # positive example\n",
    "#         train_samples_list.append(generate_pair_example(SG1, ged1_perturbed_graph, is_negative_example = False))\n",
    "#         #\n",
    "#         # ged2_perturbed_graphs = list(generate_perturbed_graphs(ged1_perturbed_graph))\n",
    "#         # for ged2_perturbed_graph in ged2_perturbed_graphs:\n",
    "#         #     # could be positive or negative example\n",
    "#         #     train_samples_list.append(compare_graphs_and_generate_pair_example(k_subgraph_annotated_graphs[subgraph_counter1], AnnotatedGraph(ged2_perturbed_graph)))\n",
    "#     # k_subgraph_to_perturbed_graphs_map[SG1] = perturbed_graphs\n",
    "\n",
    "#\n",
    "#\n",
    "# # generate all pairs examples\n",
    "# for SG1, SG1_perturbed_graphs in k_subgraph_to_perturbed_graphs_map.items():\n",
    "#     for SG2, SG2_perturbed_graphs in k_subgraph_to_perturbed_graphs_map.items():\n",
    "#\n",
    "#         if SG1 == SG2:\n",
    "#             continue # trivial pairs, or pairs already considered\n",
    "#\n",
    "#         for SG2_perturbed_graph in SG2_perturbed_graphs:\n",
    "#             train_samples_list.append(compare_graphs_and_generate_pair_example(SG1, SG2_perturbed_graph))\n",
    "#\n",
    "#         for SG1_perturbed_graph in SG1_perturbed_graphs:\n",
    "#             train_samples_list.append(compare_graphs_and_generate_pair_example(SG1_perturbed_graph, SG2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_k_subgraphs = generate_k_subgraph(reference_subgraph, k=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(random_k_subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "POSITIVE_EXAMPLES_GED_DIST_pairs_n = 20 #2000\n",
    "POSITIVE_EXAMPLES_GED_DIST = 1\n",
    "POSITIVE_EXAMPLES_k_subgraphs = random_k_subgraphs\n",
    "\n",
    "NEGATIVE_EXAMPLES_GED_DIST_pairs_n = 20\n",
    "NEGATIVE_EXAMPLES_GED_DIST = 4 #4\n",
    "NEGATIVE_EXAMPLES_k_subgraphs = random_k_subgraphs#[:20]\n",
    "\n",
    "ged_examples1, ged_examples2 = generate_positive_and_negative_ged_pairs(POSITIVE_EXAMPLES_k_subgraphs, POSITIVE_EXAMPLES_GED_DIST, POSITIVE_EXAMPLES_GED_DIST_pairs_n, NEGATIVE_EXAMPLES_k_subgraphs, NEGATIVE_EXAMPLES_GED_DIST, NEGATIVE_EXAMPLES_GED_DIST_pairs_n)\n",
    "\n",
    "ged_examples = ged_examples1 + ged_examples2\n",
    "random.shuffle(ged_examples)\n",
    "\n",
    "train_ratio = 0.7\n",
    "train_ged_examples_amount = int(len(ged_examples) * train_ratio)\n",
    "train_ged_examples = ged_examples[:train_ged_examples_amount]\n",
    "eval_ged_examples = ged_examples[train_ged_examples_amount:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(train_ged_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ged_examples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(ged_examples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k_subgraph in k_subgraphs:\n",
    "    if k_subgraphs[0].nodes == k_subgraph.nodes:\n",
    "        print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(k_subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(train_ged_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check 1-WL distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized single call for WL distance calculation\n",
    "### NOTE: Wl dist is not stable (depends which batch of graph you applied it with) ###\n",
    "# wl_dist_matrix = get_graph_wl_distances(k_subgraphs, node_label=False)\n",
    "\n",
    "# negative_pairs_wl_distances = []\n",
    "# positive_pairs_wl_distances = []\n",
    "#\n",
    "# positive_pairs_index_to_dist_map = {}\n",
    "# negative_pairs_index_to_dist_map = {}\n",
    "#\n",
    "# for i, train_sample in enumerate(train_samples_list):\n",
    "#     is_negative_sample = train_sample.is_negative_sample\n",
    "#     graph1 = train_sample.subgraph\n",
    "#     graph2 = train_sample.masked_graph\n",
    "#\n",
    "#     # s2v_graphs = generate_s2v_graphs([graph1.g, graph2.g], device, print_stats=False)\n",
    "#\n",
    "#     # distance = graph_metric_nn.forward([(s2v_graphs[0], s2v_graphs[1])]).item()\n",
    "#\n",
    "#     # wl_dist = get_graph_wl_distances([graph1.g, graph2.g], node_label=False)[0][1]\n",
    "#\n",
    "#     graph1_index, graph2_index = train_sample_indices_tuple_list[i]\n",
    "#     wl_dist = wl_dist_matrix[graph1_index][graph2_index]\n",
    "#     wl_dist = round(wl_dist, 6)\n",
    "#\n",
    "#     if is_negative_sample:\n",
    "#         negative_pairs_wl_distances.append(wl_dist)\n",
    "#         negative_pairs_index_to_dist_map[i] = wl_dist\n",
    "#     else:\n",
    "#         positive_pairs_wl_distances.append(wl_dist)\n",
    "#         positive_pairs_index_to_dist_map[i] = wl_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _ = show_wl_dist_histograms(ged_1_examples, ged_2_examples, max_examples_amount = 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# margin = 0.001\n",
    "# calc_margin_loss(torch.tensor(positive_pairs_wl_distances+negative_pairs_wl_distances), torch.cat((torch.ones(len(positive_pairs_wl_distances)), torch.zeros(len(negative_pairs_wl_distances)))), margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit GNN on k subgraph GED pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# disable debugging overhead operations\n",
    "torch.autograd.set_detect_anomaly(mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_params['margin_loss_margin_value'] = 0.5 #0.25 #0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_train_samples_amount = 50_000\n",
    "used_train_samples_list = train_ged_examples#[:used_train_samples_amount] #Needed due to performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(used_train_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint_model_path = None\n",
    "\n",
    "# val_samples_list = used_train_samples_list\n",
    "model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=input_dim, hidden_dim=128, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "solver_params[\"batch_size\"] = 512 * 8 #32 #2048 #1024 #512\n",
    "solver_params[\"k_update_plot\"] = 1\n",
    "solver_params[\"lr\"] = 1e-1\n",
    "solver_params[\"max_epochs\"] = 200 #480--\n",
    "trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=last_checkpoint_model_path)\n",
    "\n",
    "# trainer.set_existing_data_loader_paths(\n",
    "#     ['./dataloaders/1702148493.0283618.p',\n",
    "#  './dataloaders/1702148497.9922142.p',\n",
    "#  './dataloaders/1702148502.9499629.p',\n",
    "#  './dataloaders/1702148511.1819935.p'],\n",
    "# []\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train(processes_device_ids=processes_device_ids, use_existing_data_loaders=False, train_samples_list=used_train_samples_list, val_samples_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GED2 -> \"./mp/1703271648.8009052/best_model_state_dict.pt\", not seperable well\n",
    "# GED4 - > \"\"./mp/1703279923.1549501/best_model_state_dict.pt\", seperable well (not perfect but close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=\"./mp/1703411975.73806/best_model_state_dict.pt\")\n",
    "_ = graph_metric_nn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_distances, train_negative_distances = get_examples_distances(trainer, graph_metric_nn, used_train_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_negative_distances) / len(train_positive_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(train_positive_distances, \"train positive examples\", min_range=0, max_range=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_histogram(train_negative_distances, \"train negative examples\", min_range=0, max_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_margin_loss(torch.tensor(train_positive_distances+train_negative_distances), torch.cat((torch.ones(len(train_positive_distances)), torch.zeros(len(train_negative_distances)))), margin = solver_params['margin_loss_margin_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train again without rebuilding data loaders, and without the val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=input_dim, hidden_dim=64, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "# new_trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params)\n",
    "\n",
    "# new_trainer.previous_train_loader_paths = trainer.previous_train_loader_paths\n",
    "# new_trainer.previous_val_loader_paths = [None for device_id in processes_device_ids] #trainer.previous_val_loader_paths\n",
    "# new_trainer.train(processes_device_ids=processes_device_ids, use_existing_data_loaders=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = calc_performance_metrics(graph_metric_nn, used_train_samples_list, train_positive_distances, train_negative_distances, solver_params, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_positive_distances, eval_negative_distances = get_examples_distances(trainer, graph_metric_nn, eval_ged_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(eval_positive_distances, \"eval positive examples\", max_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(eval_negative_distances, \"eval negative examples\", max_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_margin_loss(torch.tensor(eval_positive_distances+eval_negative_distances), torch.cat((torch.ones(len(eval_positive_distances)), torch.zeros(len(eval_negative_distances)))), margin = solver_params['margin_loss_margin_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = calc_performance_metrics(graph_metric_nn, eval_ged_examples, eval_positive_distances, eval_negative_distances, solver_params, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Execution time profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from cProfile import Profile\n",
    "# from pstats import SortKey, Stats\n",
    "\n",
    "# with Profile() as profile:\n",
    "#     new_trainer.train(processes_device_ids=processes_device_ids, use_existing_data_loaders=True)\n",
    "#     (\n",
    "#     Stats(profile)\n",
    "#         .strip_dirs()\n",
    "#         .sort_stats(SortKey.CUMULATIVE)\n",
    "#         .print_stats()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save used_train_samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_graphs_with_negative_eaxmples = set([annotated_graph.label for annotated_graph in NEGATIVE_EXAMPLES_k_subgraphs])\n",
    "ref_graphs_with_positive_eaxmples = set([annotated_graph.label for annotated_graph in POSITIVE_EXAMPLES_k_subgraphs])\n",
    "reg_graphs_with_negative_and_positive_examples = ref_graphs_with_negative_eaxmples.intersection(ref_graphs_with_positive_eaxmples)\n",
    "\n",
    "reference_graph_to_pairs_for_training_list_map = {}\n",
    "\n",
    "for pair in used_train_samples_list:\n",
    "    ref_graph = pair.subgraph\n",
    "    ref_graph_label = pair.subgraph.label\n",
    "\n",
    "    if ref_graph_label not in reg_graphs_with_negative_and_positive_examples:\n",
    "        continue\n",
    "    \n",
    "    paired_graph = pair.masked_graph\n",
    "\n",
    "    lst = []\n",
    "    if ref_graph_label in reference_graph_to_pairs_for_training_list_map:\n",
    "        lst = reference_graph_to_pairs_for_training_list_map[ref_graph_label]\n",
    "    lst.append(pair)\n",
    "    reference_graph_to_pairs_for_training_list_map[ref_graph_label] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_base_path = f\".{os.sep}ged_train_subset\"\n",
    "if not os.path.exists(dump_base_path):\n",
    "    os.makedirs(dump_base_path)\n",
    "\n",
    "dump_path = os.path.join(dump_base_path, f\"{str(time.time())}.p\")\n",
    "with open(dump_path, 'wb') as f:\n",
    "    pickle.dump(reference_graph_to_pairs_for_training_list_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ctr = 0\n",
    "n_ctr = 0\n",
    "for k, v in reference_graph_to_pairs_for_training_list_map.items():\n",
    "    for example in v:\n",
    "        if example.is_negative_sample:\n",
    "            n_ctr += 1\n",
    "        else:\n",
    "            p_ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ctr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capacity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "num_layers = 5\n",
    "num_mlp_layers = 2\n",
    "model_factory_func = lambda device: GraphCNN(num_layers=num_layers, num_mlp_layers = num_mlp_layers, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=1, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "solver_params[\"batch_size\"] = 512 * 8\n",
    "solver_params[\"k_update_plot\"] = 10\n",
    "solver_params[\"lr\"] = 1e-1\n",
    "solver_params[\"max_epochs\"] = 200\n",
    "current_trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=\"./mp/1705969912.0095499/best_model_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = None\n",
    "hid_dim_to_val_loss_map = {}\n",
    "for hid_dim in [16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    trainer, graph_metric_nn, best_val_loss = train_model_with_hyperparams(used_train_samples_list, solver_params, problem_params, processes_device_ids, hidden_dim=hid_dim, trainer=trainer)\n",
    "    hid_dim_to_val_loss_map[hid_dim] = best_val_loss\n",
    "    print(f\"{hid_dim}: {best_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hid_dim_to_val_loss_map)\n",
    "plot_map(hid_dim_to_val_loss_map, \"hidden_dim\", \"val loss\", \"model performance vs model capacity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressivity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_GED_k_to_negative_GED_k_to_val_loss_map = {}\n",
    "pairs_n = 800\n",
    "positive_examples_k_subgraphs = random_k_subgraphs[:20]\n",
    "ged_positive_examples_cache_map = {}\n",
    "ged_negative_examples_cache_map = {}\n",
    "\n",
    "for positive_GED_k in [2, 3, 4, 5, 6, 7]:\n",
    "    negative_GED_k_to_val_loss_map = {}\n",
    "    positive_GED_k_to_negative_GED_k_to_val_loss_map[positive_GED_k] = negative_GED_k_to_val_loss_map\n",
    "\n",
    "    # prepare positive pairs dataset\n",
    "    with tqdm_joblib(tqdm(desc=\"My calculation\", total=len(positive_examples_k_subgraphs))) as progress_bar:\n",
    "        ged_positive_examples = Parallel(n_jobs=int(cpu_count()), prefer='processes')(\n",
    "            delayed(generate_random_ged_paris)(annotated_subgraph=annotated_subgraph, ged_dist=positive_GED_k, pairs_n=pairs_n, is_negative_example=False, force_exactly_pairs_n=False)\n",
    "            for annotated_subgraph in positive_examples_k_subgraphs\n",
    "        )\n",
    "    ged_positive_examples = [elem for lst in ged_positive_examples for elem in lst]\n",
    "    ged_positive_examples_cache_map[positive_GED_k] = ged_positive_examples\n",
    "    print(f\"#pos examples = {len(ged_positive_examples)}\")\n",
    "\n",
    "    for negative_GED_k in range(positive_GED_k + 1, 9):\n",
    "        print(f\"expressivity test for positive_GED_k={positive_GED_k} & negative_GED_k={negative_GED_k}\")\n",
    "\n",
    "        if negative_GED_k in ged_negative_examples_cache_map:\n",
    "            ged_negative_examples = ged_negative_examples_cache_map[negative_GED_k]\n",
    "        else:\n",
    "\n",
    "            # prepare negative pairs dataset\n",
    "            with tqdm_joblib(tqdm(desc=\"My calculation\", total=len(NEGATIVE_EXAMPLES_k_subgraphs))) as progress_bar:\n",
    "                ged_negative_examples = Parallel(n_jobs=int(cpu_count()), prefer='processes')(\n",
    "                    delayed(generate_random_ged_paris)(annotated_subgraph=annotated_subgraph, ged_dist=negative_GED_k, pairs_n=pairs_n, is_negative_example=True, force_exactly_pairs_n=False)\n",
    "                    for annotated_subgraph in NEGATIVE_EXAMPLES_k_subgraphs\n",
    "                )\n",
    "\n",
    "            ged_negative_examples = [elem for lst in ged_negative_examples for elem in lst]\n",
    "            ged_negative_examples_cache_map[negative_GED_k] = ged_negative_examples\n",
    "        print(f\"#neg examples = {len(ged_negative_examples)}\")\n",
    "\n",
    "        # combine examples to one dataset\n",
    "        ged_examples = ged_positive_examples + ged_negative_examples\n",
    "        random.shuffle(ged_examples)\n",
    "\n",
    "        train_ratio = 0.7\n",
    "        train_ged_examples_amount = int(len(ged_examples) * train_ratio)\n",
    "        train_ged_examples = ged_examples[:train_ged_examples_amount]\n",
    "        eval_ged_examples = ged_examples[train_ged_examples_amount:]\n",
    "\n",
    "        print(f\"#train set examples = {len(train_ged_examples)}\")\n",
    "\n",
    "        # train\n",
    "        trainer, graph_metric_nn, best_val_loss = train_model_with_hyperparams(train_ged_examples, solver_params, problem_params, processes_device_ids, hidden_dim=64, trainer=None)\n",
    "        negative_GED_k_to_val_loss_map[negative_GED_k] = best_val_loss\n",
    "        print(f\"negative K={negative_GED_k}: val_loss={best_val_loss}\")\n",
    "\n",
    "        # more performance metrics\n",
    "        _ = graph_metric_nn.eval()\n",
    "\n",
    "        train_positive_distances, train_negative_distances = get_examples_distances(trainer, graph_metric_nn, train_ged_examples)\n",
    "        _, _ = calc_performance_metrics(graph_metric_nn, train_ged_examples, train_positive_distances, train_negative_distances, solver_params, device)\n",
    "\n",
    "        eval_positive_distances, eval_negative_distances = get_examples_distances(trainer, graph_metric_nn, eval_ged_examples)\n",
    "        _, _ = calc_performance_metrics(graph_metric_nn, eval_ged_examples, eval_positive_distances, eval_negative_distances, solver_params, device)\n",
    "        calc_margin_loss(torch.tensor(eval_positive_distances+eval_negative_distances), torch.cat((torch.ones(len(eval_positive_distances)), torch.zeros(len(eval_negative_distances)))), margin = solver_params['margin_loss_margin_value'])\n",
    "\n",
    "        plot_histogram(train_positive_distances, \"train positive examples\", min_range=0, max_range=2)\n",
    "        plot_histogram(train_negative_distances, \"train negative examples\", min_range=0, max_range=2)\n",
    "        plot_histogram(eval_positive_distances, \"eval positive examples\", min_range=0, max_range=2)\n",
    "        plot_histogram(eval_negative_distances, \"eval negative examples\", min_range=0, max_range=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GED_experiments_map = {}\n",
    "for positive_GED_k, negative_GED_k_to_val_loss_map in positive_GED_k_to_negative_GED_k_to_val_loss_map.items():\n",
    "    for negative_GED_k, val_loss in negative_GED_k_to_val_loss_map.items():\n",
    "        GED_experiments_map[f\"{positive_GED_k}_{negative_GED_k}\"] = val_loss\n",
    "\n",
    "chart_bar_plot(GED_experiments_map, \"positive-GED-K_negative-GED-K\", \"validation loss\", \"model expressivity analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "test of 2D features space to illustrate the GED - apply MDS to separate the pairs (show the separation of the two areas) show we get a smooth wrap function using a higher dimensional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# choose reference graph s.\n",
    "reference_graph_for_GED_visualization = random_k_subgraphs[0]\n",
    "\n",
    "# generate 50 s+GED-1 graphs for positive examples (remember label)\n",
    "# generate 50 s+GED-4 graphs for negative examples (remember label)\n",
    "negative_ged_pairs, positive_ged_pairs = create_ged_visulaization_graphs(reference_graph_for_GED_visualization, label_class_examples_amount=500, positive_GED=3, negative_GED=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained pairs, and visualize some reference graphs and their pairs\n",
    "trained_pairs_path = f\".{os.sep}ged_train_subset{os.sep}1705968201.9176743.p\"\n",
    "trained_pairs_map = pickle.load(open(trained_pairs_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "for ref_graph_label, ref_graph_pairs in trained_pairs_map.items():\n",
    "    if len(ref_graph_pairs) > 35:\n",
    "        neg_pairs_ctr = 0\n",
    "        for pair in ref_graph_pairs:\n",
    "            if pair.is_negative_sample:\n",
    "                neg_pairs_ctr += 1\n",
    "        print(f\"reference graph label: {ref_graph_label}, negative pairs amount = {neg_pairs_ctr}\")\n",
    "        ctr += 1\n",
    "\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_for_trained_model(ref_graph, positive_pairs, negative_pairs, solver_params, problem_params, input_dim, num_classes):\n",
    "    for hidden_dim in [16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "        print(hidden_dim)\n",
    "        model_dump_path = get_model_dump_path(hidden_dim)\n",
    "\n",
    "        model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "\n",
    "        _, graph_metric_nn, _ = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=model_dump_path)\n",
    "\n",
    "        # calc embeddings of all pairs, apply MDS and plot\n",
    "        visualize_embeddings(graph_metric_nn, ref_graph, positive_pairs, negative_pairs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_reference_graph_pairs = trained_pairs_map[1799]\n",
    "selected_train_reference_graph = selected_train_reference_graph_pairs[0].subgraph\n",
    "selected_train_reference_graph_positive_pairs = [pair for pair in selected_train_reference_graph_pairs if pair.is_negative_sample == False]\n",
    "selected_train_reference_graph_negative_pairs = [pair for pair in selected_train_reference_graph_pairs if pair.is_negative_sample == True]\n",
    "\n",
    "visualize_embeddings_for_trained_model(selected_train_reference_graph, selected_train_reference_graph_positive_pairs, selected_train_reference_graph_negative_pairs, solver_params, problem_params, input_dim=1, num_classes=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_for_trained_model(reference_graph_for_GED_visualization, positive_ged_pairs, negative_ged_pairs, solver_params, problem_params, input_dim=1, num_classes=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = [0] + [0 for pair in positive_ged_pairs] + [1 for pair in negative_ged_pairs]\n",
    "hid_dim_to_clustering_score_maps_map = {}\n",
    "\n",
    "for hidden_dim in [16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    model_dump_path = get_model_dump_path(hidden_dim)\n",
    "    model_factory_func = lambda device: GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=1, hidden_dim=hidden_dim, output_dim=1, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "\n",
    "    _, graph_metric_nn, _ = init_embedding_net_and_trainer(model_factory_func, model_dump_path)\n",
    "\n",
    "    # calc embeddings of all pairs\n",
    "    all_embeddings = get_embeddings(graph_metric_nn, reference_graph_for_GED_visualization, positive_ged_pairs, negative_ged_pairs)\\\n",
    "    .detach().cpu().numpy()\n",
    "\n",
    "    # cluster and measure clustering quality\n",
    "    hid_dim_to_clustering_score_maps_map[hidden_dim] = measure_clustering(all_embeddings, gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim_to_clustering_score_maps_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_score_plot(hid_dim_to_clustering_score_maps_map, 'sil', 'silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_score_plot(hid_dim_to_clustering_score_maps_map, 'dav', 'davies-bouldin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_score_plot(hid_dim_to_clustering_score_maps_map, 'nmi', 'nmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric vs GED 3D plot\n",
    "# \tfor the X and Y, use radius-s of GED, e.g. for radius =1, all GED-1 examples (against a fixed reference graph)\n",
    "\n",
    "# interactive mode may cause issues, see: https://stackoverflow.com/questions/51922480/javascript-error-ipython-is-not-defined-in-jupyterlab\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# \twhat about the sampled graphs in the space, are they random? or they are sampled real subgraphs from the full graph?\n",
    "# \t\tallow both configurations:\n",
    "# \t\t\tall GED\n",
    "# \t\t\tjust existing sampled subgraphs GED (we can color them among all GED actually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reference_graph_model_loss_space(solver_params, problem_params, 1024, random_k_subgraphs[10], GED_dists = [1, 4], max_samples_per_radius = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_ged_radiuses_graphs_map = visualize_reference_graph_model_loss_space(solver_params, problem_params, 1024, random_k_subgraphs[15], GED_dists = [1, 4, 9], max_samples_per_radius = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_ged_radiuses_graphs_map = visualize_reference_graph_model_loss_space(solver_params, problem_params, 1024, random_k_subgraphs[15], GED_dists = [1, 4, 9], max_samples_per_radius = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reference_graph_model_loss_space(solver_params, problem_params, 1024, reference_graph_for_GED_visualization, GED_dists = [3, 6], max_samples_per_radius = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ged_dist_to_pairs_map = {1: selected_train_reference_graph_positive_pairs, 4: selected_train_reference_graph_negative_pairs}\n",
    "visualize_reference_graph_model_loss_space(solver_params, problem_params, 1024, selected_train_reference_graph, GED_dists = train_ged_dist_to_pairs_map, max_samples_per_radius = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_distances, train_negative_distances = calc_margin_loss_for_pairs(trainer, graph_metric_nn, solver_params, selected_train_reference_graph_positive_pairs + selected_train_reference_graph_negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(train_positive_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(train_negative_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, graph_metric_nn = create_metric_and_trainer(hidden_dim=1024, solver_params=solver_params, problem_params=problem_params)\n",
    "_ = graph_metric_nn.eval()\n",
    "epoch_val_loss = 0\n",
    "val_samples_list = positive_ged_pairs + negative_ged_pairs\n",
    "stub_train_samples_list = val_samples_list[:1]\n",
    "train_loaders, val_loaders = trainer.get_data_loaders(stub_train_samples_list, val_samples_list, 0, ['cpu'])\n",
    "val_loader = val_loaders[0]\n",
    "\n",
    "for val_batch in val_loader:\n",
    "    val_loss = trainer.calculate_loss_for_batch(val_batch, is_train=False)\n",
    "    epoch_val_loss += val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_train_reference_graph_pairs = [pair for _, train_reference_graph_pairs in trained_pairs_map.items() for pair in train_reference_graph_pairs]\n",
    "train_positive_distances, train_negative_distances = get_examples_distances(trainer, graph_metric_nn, ged_examples1 + ged_examples2)\n",
    "\n",
    "calc_margin_loss(torch.tensor(train_positive_distances+train_negative_distances), torch.cat((torch.ones(len(train_positive_distances)), torch.zeros(len(train_negative_distances)))), margin = solver_params['margin_loss_margin_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(train_positive_distances, \"positive pair distances\", min_range=0, max_range=1)\n",
    "plot_histogram(train_negative_distances, \"negative pair distances\", min_range=0, max_range=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_ged_pairs(trainer, graph_metric_nn, 1, multiple_ged_radiuses_graphs_map[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_ged_pairs(trainer, graph_metric_nn, 4, multiple_ged_radiuses_graphs_map[4], max_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_ged_pairs(trainer, graph_metric_nn, 4, multiple_ged_radiuses_graphs_map[4], max_range=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_ged_pairs(trainer, graph_metric_nn, 4, multiple_ged_radiuses_graphs_map[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_ged_pairs(trainer, graph_metric_nn, 9, multiple_ged_radiuses_graphs_map[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_ged_pairs(trainer, graph_metric_nn, 9, multiple_ged_radiuses_graphs_map[9], max_range=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter generate_pairs_data_set\n",
      "graph has 16 nodes\n",
      "starting generating subgraphs\n",
      "start generate_k_subgraphs\n",
      "enter generate_k_subgraphs\n",
      "total time for finished all_connected_subgraphs (total of 6205 graphs):0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #52 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #34 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #67 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #83 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #23 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #35 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #38 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #2 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #32 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #40 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #56 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #53 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #57 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #76 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #6 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #61 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #48 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #79 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #41 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #27 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #9 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #55 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #65 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #63 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #72 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #75 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #74 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #54 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #50 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #66 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #46 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #20 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #12 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #62 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #21 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #60 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #78 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #59 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #19 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #82 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #24 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #73 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #3 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #33 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #13 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #45 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #68 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #70 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #8 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #51 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #64 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #26 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #69 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #81 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #15 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #77 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #84 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #14 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #71 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #4 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #43 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #0 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #25 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #11 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #7 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #10 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #18 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #37 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #22 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #47 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #16 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #44 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #39 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #85 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #5 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #80 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #42 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #30 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #49 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #28 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #1 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #36 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #29 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #31 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #58 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #17 finished, chunk size=71:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #87 finished, chunk size=28:0s\n",
      "enter generate_k_subgraphs_for_chunk\n",
      "total time for Chunk #86 finished, chunk size=71:0s\n",
      "total time for finished generating subgraphs:2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brute_force_k_subgraph_annotated_graphs = generate_pairs_data_set(circuit_base_dir=circuit_base_dir, circuit_file_name = 'comp1_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brute_force_k_subgraph_annotated_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437999\n",
      "432958\n",
      "427917\n",
      "422876\n",
      "417835\n",
      "412794\n",
      "407753\n",
      "402712\n",
      "397671\n",
      "392630\n",
      "387589\n",
      "382548\n",
      "377507\n",
      "372466\n",
      "367425\n",
      "362384\n",
      "357343\n",
      "352302\n",
      "347261\n",
      "342220\n",
      "337179\n",
      "332138\n",
      "327097\n",
      "322056\n",
      "317015\n",
      "311974\n",
      "306933\n",
      "301892\n",
      "296851\n",
      "291810\n",
      "286769\n",
      "281728\n",
      "276687\n",
      "271646\n",
      "266605\n",
      "261564\n",
      "256523\n",
      "251482\n",
      "246441\n",
      "241400\n",
      "236359\n",
      "231318\n",
      "226277\n",
      "221236\n",
      "216195\n",
      "211154\n",
      "206113\n",
      "201072\n",
      "196031\n",
      "190990\n",
      "185949\n",
      "180908\n",
      "175867\n",
      "170826\n",
      "165785\n",
      "160744\n",
      "155703\n",
      "150662\n",
      "145621\n",
      "140580\n",
      "135539\n",
      "130498\n",
      "125457\n",
      "120416\n",
      "115375\n",
      "110334\n",
      "105293\n",
      "100252\n",
      "95211\n",
      "90170\n",
      "85129\n",
      "80088\n",
      "75047\n",
      "70006\n",
      "64965\n",
      "59924\n",
      "54883\n",
      "49842\n",
      "44801\n",
      "39760\n",
      "34719\n",
      "29678\n",
      "24637\n",
      "19596\n",
      "14555\n",
      "9514\n",
      "4473\n",
      "378\n"
     ]
    }
   ],
   "source": [
    "brute_force_train_samples_list = []\n",
    "for chunk_index in range(0, 88):\n",
    "    with open(f'brute_force_pairs{os.sep}{chunk_index}.p', 'rb') as file:\n",
    "        tmp_brute_force_train_samples_list = pickle.load(file)\n",
    "    print(len(tmp_brute_force_train_samples_list))\n",
    "    brute_force_train_samples_list += tmp_brute_force_train_samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - make sure no ismorphic graphs, if there are make some manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_train_samples_list = brute_force_train_samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19247910"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_train_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "num_layers = 5\n",
    "num_mlp_layers = 2\n",
    "model_factory_func = lambda device: GraphCNN(num_layers=num_layers, num_mlp_layers = num_mlp_layers, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=1, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device)\n",
    "solver_params[\"batch_size\"] = 512 * 8\n",
    "solver_params[\"k_update_plot\"] = 1\n",
    "solver_params[\"lr\"] = 1e-1\n",
    "solver_params[\"max_epochs\"] = 200\n",
    "current_trainer, graph_metric_nn, model = init_embedding_net_and_trainer(model_factory_func, solver_params, problem_params, graph_metric_nn_checkpoint_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_trainer.train(processes_device_ids=processes_device_ids, use_existing_data_loaders=False, train_samples_list=used_train_samples_list, val_samples_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
