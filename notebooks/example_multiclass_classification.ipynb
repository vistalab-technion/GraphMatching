{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/rssalessio/PytorchRBFLayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "1199b75c",
   "metadata": {},
   "source": [
    "# 3-class classification example\n",
    "\n",
    "In this example we try to learn a model that is able to classify 3 classes drawn from 3 different normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff4f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from rbf_layer.rbf_layer import RBFLayer\n",
    "from rbf_layer.rbf_utils import l_norm, rbf_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8186575",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3417eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate dataset\n",
    "# N_training = 100\n",
    "# N_validation = 50\n",
    "# N = N_training + N_validation\n",
    "#\n",
    "#\n",
    "# X0 = np.array([-1, 0]).T + 0.5 * np.random.normal(size=(N, 2))\n",
    "# X1 = np.array([1, 0]).T +  0.5 * np.random.normal(size=(N, 2))\n",
    "# X2 = np.array([0, 1]).T + 0.3 * np.random.normal(size=(N, 2))\n",
    "# X = np.concatenate([X0, X1, X2])\n",
    "#\n",
    "# labels = np.zeros((3*N, 1))\n",
    "# labels[N:2*N] = 1\n",
    "# labels[2*N:] = 2\n",
    "#\n",
    "# # Training dataset\n",
    "# indices = np.random.permutation(3 * N)\n",
    "# trn_indices, val_indices = indices[:N_training], indices[N_training:]\n",
    "# Tdataset = ([torch.tensor(X[trn_indices], dtype=torch.float32), torch.tensor(labels[trn_indices], dtype=torch.float32)])\n",
    "# Vdataset = ([torch.tensor(X[val_indices], dtype=torch.float32), torch.tensor(labels[val_indices], dtype=torch.float32)])\n",
    "#\n",
    "# # Plot dataset\n",
    "# plt.scatter(X0[:, 0], X0[:, 1])\n",
    "# plt.scatter(X1[:, 0], X1[:, 1])\n",
    "# plt.scatter(X2[:, 0], X2[:, 1])\n",
    "# plt.grid()\n",
    "# plt.title('Feature space')\n",
    "# plt.xlabel('Feature 1')\n",
    "# plt.ylabel('Feature 2')\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from subgraph_matching_via_nn.data.data_loaders import load_graph\n",
    "import os\n",
    "\n",
    "goal_subcircuit_name = 'alu'\n",
    "DATA_PATH = 'C:/Users/kogan/OneDrive/Desktop/Research/AMIT/GraphMatching/subgraph_matching_via_nn/data/subcircuits/'\n",
    "desktop = pathlib.Path(DATA_PATH)\n",
    "subgraphs = []\n",
    "labels = []\n",
    "for circuit_dir in desktop.iterdir():\n",
    "    if circuit_dir.is_dir():\n",
    "        for subcircuit_file in circuit_dir.iterdir():\n",
    "            if subcircuit_file.is_file():\n",
    "                file_name = subcircuit_file.name\n",
    "                if file_name == 'full_graph.p':\n",
    "                    file_rel_path = f\"{os.sep}{file_name}\"\n",
    "                    loader_params = {\n",
    "                     'data_path' : str(circuit_dir),\n",
    "                     'g_full_path': file_rel_path,\n",
    "                     'g_sub_path': file_rel_path}\n",
    "\n",
    "                    sub_graph = \\\n",
    "                        load_graph(type='subcircuit',\n",
    "                                   loader_params=loader_params)\n",
    "\n",
    "                    if goal_subcircuit_name in circuit_dir.name:\n",
    "                        labels.append(1)\n",
    "                    else:\n",
    "                        # continue #TODO?\n",
    "                        labels.append(0)\n",
    "                    subgraphs.append(sub_graph)\n",
    "\n",
    "labels = np.array(labels, dtype='float32')\n",
    "N = len(subgraphs)\n",
    "N_training = int(2 / 3 * N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "subgraphs = []\n",
    "labels = []\n",
    "\n",
    "circuit_base_dir = 'C:\\\\Users\\\\kogan\\\\OneDrive\\\\Desktop\\\\Research\\\\AMIT\\\\GraphMatching\\\\subgraph_matching_via_nn\\\\data\\\\subcircuits\\\\'\n",
    "for circuit_file_name in ['adder_4', 'alu_4', 'alu_8', 'alu_16', 'alu_32', 'mul_4_4', 'mul_4_8', 'mul_8_8', 'mul_16_32']:\n",
    "    file_rel_path = 'full_graph.p'\n",
    "    circuit_dir = f\"{circuit_base_dir}{circuit_file_name}{os.sep}\"\n",
    "    loader_params = {\n",
    "     'data_path' : str(circuit_dir),\n",
    "     'g_full_path': file_rel_path,\n",
    "     'g_sub_path': file_rel_path}\n",
    "\n",
    "    sub_graph = \\\n",
    "        load_graph(type='subcircuit',\n",
    "                   loader_params=loader_params)\n",
    "    subgraphs.append(sub_graph)\n",
    "    labels.append(0)\n",
    "labels[0] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "N = len(subgraphs)\n",
    "N_training = int(2 / 3 * N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subgraphs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def prepare_x_and_labels(subgraphs, labels, indices, N_training):\n",
    "    trn_indices, val_indices = indices[:N_training], indices[N_training:]\n",
    "\n",
    "    trn_x = [subgraphs[ind] for ind in trn_indices]\n",
    "    trn_label = [labels[ind] for ind in trn_indices]\n",
    "    validation_x = [subgraphs[ind] for ind in val_indices]\n",
    "    validation_label = [labels[ind] for ind in val_indices]\n",
    "\n",
    "    for ind in indices:\n",
    "        if labels[ind] == 1:\n",
    "            break\n",
    "    print(ind)\n",
    "    compared_subgraph = subgraphs[ind]\n",
    "\n",
    "    return trn_x, trn_label, validation_x, validation_label, compared_subgraph\n",
    "\n",
    "# Training dataset\n",
    "indices = np.random.permutation(N)\n",
    "trn_x, trn_label, validation_x, validation_label, compared_subgraph = prepare_x_and_labels(subgraphs, labels, indices, N_training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "N_training = N\n",
    "trn_x = validation_x = subgraphs\n",
    "trn_label = validation_label = labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 0, 0, 0, 0, 0, 0, 0, 0]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 0, 0, 0, 0, 0, 0, 0, 0]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# for subgraph in subgraphs:\n",
    "#     print(rbf_graph_model(subgraph))\n",
    "\n",
    "# for id, label in enumerate(labels):\n",
    "#     if label == 1:\n",
    "#         print(id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define full model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from notebooks.rbf_metric import GCNEmbeddingNetwork, RBFGraphModel\n",
    "\n",
    "embedding_features_size = 3\n",
    "embedding_model = GCNEmbeddingNetwork(1, embedding_features_size)\n",
    "\n",
    "rbf_graph_model = RBFGraphModel(embedding_model, embedding_features_size)\n",
    "\n",
    "# embedding_model = GCNEmbeddingNetwork(1, 3)\n",
    "# some_A = subgraphs[0].A_full\n",
    "# res = embedding_model(some_A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "ba4d103e",
   "metadata": {},
   "source": [
    "# Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29695c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0 loss=48.59091430252944\n",
      "\n",
      "epoch 1 loss=48.503508748313294\n",
      "\n",
      "epoch 2 loss=42.26427682369152\n",
      "\n",
      "epoch 3 loss=47.56667860723412\n",
      "\n",
      "epoch 4 loss=47.546267710323285\n",
      "\n",
      "epoch 5 loss=58.50940748710554\n",
      "\n",
      "epoch 6 loss=39.994474375029526\n",
      "\n",
      "epoch 7 loss=41.78227340425431\n",
      "\n",
      "epoch 8 loss=59.93453624303996\n",
      "\n",
      "epoch 9 loss=47.95115553410864\n",
      "\n",
      "epoch 10 loss=51.68790844652606\n",
      "\n",
      "epoch 11 loss=60.08945792782217\n",
      "\n",
      "epoch 12 loss=48.35503865349827\n",
      "\n",
      "epoch 13 loss=46.759260303813406\n",
      "\n",
      "epoch 14 loss=50.54887908000389\n",
      "\n",
      "epoch 15 loss=41.19282300137268\n",
      "\n",
      "epoch 16 loss=48.747275470465404\n",
      "\n",
      "epoch 17 loss=59.22604486916688\n",
      "\n",
      "epoch 18 loss=49.98732204259607\n",
      "\n",
      "epoch 19 loss=60.83136632932004\n",
      "\n",
      "epoch 20 loss=38.94177680648993\n",
      "\n",
      "epoch 21 loss=49.626424867658606\n",
      "\n",
      "epoch 22 loss=61.54340633169467\n",
      "\n",
      "epoch 23 loss=52.049920349306916\n",
      "\n",
      "epoch 24 loss=60.02195679685182\n",
      "\n",
      "epoch 25 loss=48.30190497046791\n",
      "\n",
      "epoch 26 loss=57.464835375189296\n",
      "\n",
      "epoch 27 loss=41.621472274940544\n",
      "\n",
      "epoch 28 loss=50.7130088408924\n",
      "\n",
      "epoch 29 loss=49.471212358641914\n",
      "\n",
      "epoch 30 loss=59.644376242643865\n",
      "\n",
      "epoch 31 loss=58.444485804302786\n",
      "\n",
      "epoch 32 loss=68.13393494375588\n",
      "\n",
      "epoch 33 loss=49.51399381110586\n",
      "\n",
      "epoch 34 loss=49.07555051587278\n",
      "\n",
      "epoch 35 loss=58.69333524558892\n",
      "\n",
      "epoch 36 loss=58.03255081386346\n",
      "\n",
      "epoch 37 loss=50.403190870985675\n",
      "\n",
      "epoch 38 loss=49.80118458036236\n",
      "\n",
      "epoch 39 loss=48.670402402492115\n",
      "\n",
      "epoch 40 loss=48.762485123069695\n",
      "\n",
      "epoch 41 loss=38.995016761130415\n",
      "\n",
      "epoch 42 loss=38.3118248077832\n",
      "\n",
      "epoch 43 loss=67.6047878657878\n",
      "\n",
      "epoch 44 loss=58.75460622250408\n",
      "\n",
      "epoch 45 loss=50.98167605353128\n",
      "\n",
      "epoch 46 loss=51.08866685895401\n",
      "\n",
      "epoch 47 loss=49.02571682373533\n",
      "\n",
      "epoch 48 loss=60.393101443426154\n",
      "\n",
      "epoch 49 loss=58.14079916403018\n",
      "\n",
      "epoch 50 loss=52.02294763328521\n",
      "\n",
      "epoch 51 loss=58.9831327967313\n",
      "\n",
      "epoch 52 loss=49.867440462245035\n",
      "\n",
      "epoch 53 loss=59.81807740873905\n",
      "\n",
      "epoch 54 loss=49.39350543248246\n",
      "\n",
      "epoch 55 loss=59.77293945799066\n",
      "\n",
      "epoch 56 loss=60.47304327753919\n",
      "\n",
      "epoch 57 loss=37.155603772843094\n",
      "\n",
      "epoch 58 loss=59.7586260357297\n",
      "\n",
      "epoch 59 loss=49.49008288997704\n",
      "\n",
      "epoch 60 loss=49.81307658940165\n",
      "\n",
      "epoch 61 loss=41.80294894653475\n",
      "\n",
      "epoch 62 loss=39.74306628490168\n",
      "\n",
      "epoch 63 loss=48.07515890592165\n",
      "\n",
      "epoch 64 loss=48.608280845026286\n",
      "\n",
      "epoch 65 loss=38.433862423481095\n",
      "\n",
      "epoch 66 loss=50.59883963018745\n",
      "\n",
      "epoch 67 loss=60.22700772311149\n",
      "\n",
      "epoch 68 loss=38.36185154301255\n",
      "\n",
      "epoch 69 loss=49.952361531702735\n",
      "\n",
      "epoch 70 loss=38.92721692800577\n",
      "\n",
      "epoch 71 loss=37.38736114093619\n",
      "\n",
      "epoch 72 loss=40.72120534737918\n",
      "\n",
      "epoch 73 loss=48.64127344122104\n",
      "\n",
      "epoch 74 loss=37.75918894842464\n",
      "\n",
      "epoch 75 loss=57.724602595143764\n",
      "\n",
      "epoch 76 loss=38.56479968641374\n",
      "\n",
      "epoch 77 loss=59.42041364539619\n",
      "\n",
      "epoch 78 loss=56.88750610535197\n",
      "\n",
      "epoch 79 loss=57.713005693367904\n",
      "\n",
      "epoch 80 loss=50.993564508256995\n",
      "\n",
      "epoch 81 loss=57.55078785996674\n",
      "\n",
      "epoch 82 loss=59.77015769433147\n",
      "\n",
      "epoch 83 loss=57.33242502517011\n",
      "\n",
      "epoch 84 loss=51.83739075486167\n",
      "\n",
      "epoch 85 loss=42.48288688608254\n",
      "\n",
      "epoch 86 loss=59.40212278467498\n",
      "\n",
      "epoch 87 loss=58.86981468123193\n",
      "\n",
      "epoch 88 loss=58.505841171004214\n",
      "\n",
      "epoch 89 loss=69.25620740607181\n",
      "\n",
      "epoch 90 loss=57.41923081859222\n",
      "\n",
      "epoch 91 loss=49.29710910766241\n",
      "\n",
      "epoch 92 loss=57.11673790023511\n",
      "\n",
      "epoch 93 loss=47.76906812383956\n",
      "\n",
      "epoch 94 loss=49.035771510912745\n",
      "\n",
      "epoch 95 loss=39.912824927808465\n",
      "\n",
      "epoch 96 loss=49.58597580784116\n",
      "\n",
      "epoch 97 loss=50.59364069745201\n",
      "\n",
      "epoch 98 loss=48.3782169204274\n",
      "\n",
      "epoch 99 loss=41.090435082873356\n",
      "\n",
      "epoch 100 loss=41.66118320497118\n",
      "\n",
      "epoch 101 loss=55.467768321053\n",
      "\n",
      "epoch 102 loss=48.57095761671135\n",
      "\n",
      "epoch 103 loss=39.46573888720751\n",
      "\n",
      "epoch 104 loss=39.085910381348114\n",
      "\n",
      "epoch 105 loss=58.9128846831546\n",
      "\n",
      "epoch 106 loss=48.91919399141919\n",
      "\n",
      "epoch 107 loss=50.114977680081665\n",
      "\n",
      "epoch 108 loss=48.74231030022328\n",
      "\n",
      "epoch 109 loss=49.6753791569087\n",
      "\n",
      "epoch 110 loss=39.827847652707476\n",
      "\n",
      "epoch 111 loss=38.6583698156309\n",
      "\n",
      "epoch 112 loss=51.32000066287215\n",
      "\n",
      "epoch 113 loss=51.29055396784298\n",
      "\n",
      "epoch 114 loss=48.15295595928161\n",
      "\n",
      "epoch 115 loss=52.40573133150346\n",
      "\n",
      "epoch 116 loss=40.122976472664035\n",
      "\n",
      "epoch 117 loss=49.98884757609465\n",
      "\n",
      "epoch 118 loss=49.165564834595735\n",
      "\n",
      "epoch 119 loss=48.42214776513109\n",
      "\n",
      "epoch 120 loss=49.22714810603589\n",
      "\n",
      "epoch 121 loss=49.11279098290762\n",
      "\n",
      "epoch 122 loss=60.73184499919801\n",
      "\n",
      "epoch 123 loss=40.72903934514247\n",
      "\n",
      "epoch 124 loss=52.006540390061986\n",
      "\n",
      "epoch 125 loss=50.818847198402835\n",
      "\n",
      "epoch 126 loss=50.09859189146476\n",
      "\n",
      "epoch 127 loss=38.803059722007134\n",
      "\n",
      "epoch 128 loss=48.60788085136402\n",
      "\n",
      "epoch 129 loss=60.51050642285324\n",
      "\n",
      "epoch 130 loss=60.14093509614975\n",
      "\n",
      "epoch 131 loss=50.6249794103085\n",
      "\n",
      "epoch 132 loss=50.2020575593628\n",
      "\n",
      "epoch 133 loss=57.52539015982937\n",
      "\n",
      "epoch 134 loss=49.25416427126957\n",
      "\n",
      "epoch 135 loss=57.8858382624881\n",
      "\n",
      "epoch 136 loss=49.56709867269391\n",
      "\n",
      "epoch 137 loss=50.85628080314271\n",
      "\n",
      "epoch 138 loss=58.16423632284605\n",
      "\n",
      "epoch 139 loss=49.78702914908591\n",
      "\n",
      "epoch 140 loss=56.84743634052048\n",
      "\n",
      "epoch 141 loss=49.5901382865961\n",
      "\n",
      "epoch 142 loss=57.979192579199406\n",
      "\n",
      "epoch 143 loss=48.56993972972761\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6580/2878144343.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[1;31m# Compute loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m         \u001B[0moptimiser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcalc_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m         \u001B[0mepoch_trn_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6580/2878144343.py\u001B[0m in \u001B[0;36mcalc_loss\u001B[1;34m(x, labels)\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[1;31m#TODO: calc distance vs trn_x[0]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[0mcompared_embedding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrbf_graph_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcompared_subgraph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mrbf_graph_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMSELoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompared_embedding\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0my_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6580/2878144343.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[1;31m#TODO: calc distance vs trn_x[0]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[0mcompared_embedding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrbf_graph_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcompared_subgraph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mrbf_graph_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMSELoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompared_embedding\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0my_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kogan\\.virtualenvs\\subcircuit_recognition-mmb-fima\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Desktop\\Research\\AMIT\\GraphMatching\\notebooks\\rbf_metric.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, g)\u001B[0m\n\u001B[0;32m     68\u001B[0m         \u001B[0mA\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mA_full\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m         \u001B[0memb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;31m# for name, param in self.embedding_model.conv1.named_parameters():\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m         \u001B[1;31m#     print(name, param.grad)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kogan\\.virtualenvs\\subcircuit_recognition-mmb-fima\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Desktop\\Research\\AMIT\\GraphMatching\\notebooks\\rbf_metric.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, A, x)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mA\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[0medge_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mA\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import custom_bwd, custom_fwd\n",
    "\n",
    "class DifferentiableClamp(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    In the forward pass this operation behaves like torch.clamp.\n",
    "    But in the backward pass its gradient is 1 everywhere, as if instead of clamp one had used the identity function.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @custom_fwd\n",
    "    def forward(ctx, input, min, max):\n",
    "        return input.clamp(min=min, max=max)\n",
    "\n",
    "    @staticmethod\n",
    "    @custom_bwd\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.clone(), None, None\n",
    "\n",
    "\n",
    "def dclamp(input, min, max):\n",
    "    \"\"\"\n",
    "    Like torch.clamp, but with a constant 1-gradient.\n",
    "    :param input: The input that is to be clamped.\n",
    "    :param min: The minimum value of the output.\n",
    "    :param max: The maximum value of the output.\n",
    "    \"\"\"\n",
    "    return DifferentiableClamp.apply(input, min, max)\n",
    "\n",
    "# rbf_graph_model.train(mode=True)\n",
    "\n",
    "def calc_loss(x, labels):\n",
    "    #TODO: calc distance vs trn_x[0]\n",
    "    compared_embedding = rbf_graph_model(compared_subgraph).to(dtype=torch.float64)\n",
    "    y = [rbf_graph_model(x_).to(dtype=torch.float64) for x_ in x]\n",
    "    y = [torch.nn.MSELoss()(y_, compared_embedding) for y_ in y]\n",
    "\n",
    "    predictions = torch.stack(y)\n",
    "    # predictions = torch.cat(y, dim=0).squeeze(1)\n",
    "    # predictions = dclamp(predictions, 0, 1)\n",
    "    predictions = torch.sigmoid(predictions)#.reshape(-1)\n",
    "\n",
    "    targets = torch.tensor(labels, dtype=torch.float64)\n",
    "\n",
    "    try:\n",
    "        loss = nn.BCELoss()(predictions, targets)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        print(predictions)\n",
    "        print(\"BUG\")\n",
    "    return loss\n",
    "\n",
    "optimiser = torch.optim.Adam(rbf_graph_model.parameters(), lr=5e-6)\n",
    "# optimiser = torch.optim.SGD(rbf_graph_model.parameters(), lr=1e-6, momentum=0.9, weight_decay=5e-1)\n",
    "epochs_number = 2000\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimiser, T_max=epochs_number)\n",
    "epoch = 0\n",
    "batch_size = N_training\n",
    "trn_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    indices = np.random.permutation(N_training)\n",
    "    batch_idx = 0\n",
    "    epoch_trn_losses = []\n",
    "    epoch_val_losses = []\n",
    "\n",
    "    # Epoch training\n",
    "    while batch_idx < N_training:\n",
    "        idxs = indices[batch_idx:batch_idx + batch_size]\n",
    "        x = [trn_x[idx] for idx in idxs]\n",
    "        labels = [trn_label[idx] for idx in idxs]\n",
    "        \n",
    "        # Compute loss\n",
    "        optimiser.zero_grad()\n",
    "        loss = calc_loss(x, labels)\n",
    "        epoch_trn_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # for name, param in rbf_graph_model.named_parameters():\n",
    "        #     print(name, param.grad)\n",
    "        optimiser.step()\n",
    "        batch_idx += batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute validation\n",
    "            loss = calc_loss(validation_x, validation_label)\n",
    "\n",
    "            epoch_val_losses.append(loss.item())\n",
    "    print(f\"\\nepoch {epoch} loss={loss.item()}\")\n",
    "\n",
    "    trn_losses.append(np.mean(epoch_trn_losses))\n",
    "    val_losses.append(np.mean(epoch_val_losses))\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "plt.plot(trn_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Training plot')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 0, 0, 0, 0, 0, 0, 0, 0]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "rbf_graph_model.eval()\n",
    "compared_embedding = rbf_graph_model(compared_subgraph).to(dtype=torch.float64)\n",
    "y = [rbf_graph_model(x_).to(dtype=torch.float64) for x_ in subgraphs]\n",
    "y = [torch.nn.MSELoss()(y_, compared_embedding) for y_ in y]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 0, 0, 0, 0, 0, 0, 0]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for ind, label in enumerate(labels):\n",
    "    if label == 1:\n",
    "        print(ind)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor(0., dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(0.6836, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(28.6607, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(207.9005, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(1060.0068, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(0.6568, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(13.8747, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(44.5584, dtype=torch.float64, grad_fn=<MseLossBackward>),\n tensor(900.3855, dtype=torch.float64, grad_fn=<MseLossBackward>)]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "32c3474c",
   "metadata": {},
   "source": [
    "## Plot kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels = rbf.get_kernels_centers.numpy()\n",
    "# shapes = rbf.get_shapes.numpy()\n",
    "#\n",
    "# def fun(x, y, center, shape):\n",
    "#     diff = center.T - [x, y]\n",
    "#     r = np.linalg.norm(diff, axis=0)\n",
    "#     return np.exp(-(shape * r) ** 2)\n",
    "#\n",
    "# x = y = np.arange(-2.5, 2.5, 0.05)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "# fig, ax = plt.subplots()\n",
    "#\n",
    "# for i in range(3):\n",
    "#     center = kernels[i][:, None].repeat(10000, axis=1).T\n",
    "#     zs = np.array(fun(X.ravel(), Y.ravel(), center, shapes[i].repeat(10000)))\n",
    "#     Z = zs.reshape(X.shape)\n",
    "#\n",
    "#     CS = ax.contour(X, Y, Z)\n",
    "#     ax.clabel(CS, inline=True, fontsize=10)\n",
    "# ax.set_title('Learnt kernels')\n",
    "# ax.set_xlabel('Feature 1')\n",
    "# ax.set_ylabel('Feature 2')\n",
    "# ax.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b741a",
   "metadata": {},
   "source": [
    "# Plot decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d53049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = y = np.arange(-2.5, 2.5, 0.05)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "#\n",
    "# # Compute model prediction\n",
    "# inp = torch.tensor([X.ravel(), Y.ravel()]).T\n",
    "# Z = rbf(inp).argmax(dim=1).detach().numpy()\n",
    "#\n",
    "# # Put the result into a color plot\n",
    "# Z = Z.reshape(X.shape)\n",
    "# plt.contourf(X, Y, Z, cmap=cm.Pastel1)\n",
    "#\n",
    "# # Plot dataset\n",
    "# plt.scatter(X0[:, 0], X0[:, 1], c='r')\n",
    "# plt.scatter(X1[:, 0], X1[:, 1], c='m')\n",
    "# plt.scatter(X2[:, 0], X2[:, 1], c='gray')\n",
    "#\n",
    "# plt.title('Decision boundaries')\n",
    "# plt.xlabel('Feature 1')\n",
    "# plt.ylabel('Feature 2')\n",
    "# plt.plot()\n",
    "# plt.savefig('example_classification_img.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply KDE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#TODO\n",
    "# https://github.com/sampath9dasari/NaiveBayesClassifier-KDE/blob/master/NaiveBayes_with_KDE.ipynb\n",
    "\n",
    "x_train = [embedding_model(sample.A_full).detach().numpy() for sample in trn_x]\n",
    "y_train = trn_label\n",
    "x_test = [embedding_model(sample.A_full).detach().numpy() for sample in validation_x]\n",
    "y_test = validation_label\n",
    "\n",
    "gaussian_model = GaussianNB()\n",
    "gaussian_model.fit(x_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaussian_model.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaussian_model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# enhance dataset: can append distances to the embedding (the distance from the graph) for graphs which we know should not be similar\n",
    "#TODO\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}