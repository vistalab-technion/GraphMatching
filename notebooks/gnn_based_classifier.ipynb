{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from subgraph_matching_via_nn.data.data_loaders import load_graph\n",
    "from powerful_gnns.util import S2VGraph\n",
    "from powerful_gnns.util import load_data_given_graph_list_and_label_map\n",
    "from powerful_gnns.models.graphcnn import GraphCNN\n",
    "from powerful_gnns.util import separate_data\n",
    "from powerful_gnns.classifier_training import train, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "goal_subcircuit_name = 'alu'\n",
    "DATA_PATH = 'C:/Users/kogan/OneDrive/Desktop/Research/AMIT/GraphMatching/subgraph_matching_via_nn/data/subcircuits/'\n",
    "desktop = pathlib.Path(DATA_PATH)\n",
    "subgraphs = []\n",
    "labels = []\n",
    "for circuit_dir in desktop.iterdir():\n",
    "    if circuit_dir.is_dir():\n",
    "        for subcircuit_file in circuit_dir.iterdir():\n",
    "            if subcircuit_file.is_file():\n",
    "                file_name = subcircuit_file.name\n",
    "                if file_name == 'full_graph.p':\n",
    "                    file_rel_path = f\"{os.sep}{file_name}\"\n",
    "                    loader_params = {\n",
    "                     'data_path' : str(circuit_dir),\n",
    "                     'g_full_path': file_rel_path,\n",
    "                     'g_sub_path': file_rel_path}\n",
    "\n",
    "                    sub_graph = \\\n",
    "                        load_graph(type='subcircuit',\n",
    "                                   loader_params=loader_params)\n",
    "\n",
    "                    if goal_subcircuit_name in circuit_dir.name:\n",
    "                        labels.append(1)\n",
    "                    else:\n",
    "                        # continue #TODO?\n",
    "                        labels.append(0)\n",
    "                    subgraphs.append(sub_graph)\n",
    "\n",
    "labels = np.array(labels, dtype='float32')\n",
    "N = len(subgraphs)\n",
    "N_training = int(2 / 3 * N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "subgraphs = []\n",
    "labels = []\n",
    "\n",
    "circuit_base_dir = 'C:\\\\Users\\\\kogan\\\\OneDrive\\\\Desktop\\\\Research\\\\AMIT\\\\GraphMatching\\\\subgraph_matching_via_nn\\\\data\\\\subcircuits\\\\'\n",
    "for circuit_file_name in ['adder_4', 'alu_4', 'alu_8', 'alu_16', 'alu_32', 'mul_4_4', 'mul_4_8', 'mul_8_8', 'mul_16_16', 'mul_16_32']:\n",
    "    file_rel_path = 'full_graph.p'\n",
    "    circuit_dir = f\"{circuit_base_dir}{circuit_file_name}{os.sep}\"\n",
    "    loader_params = {\n",
    "     'data_path' : str(circuit_dir),\n",
    "     'g_full_path': file_rel_path,\n",
    "     'g_sub_path': file_rel_path}\n",
    "\n",
    "    sub_graph = \\\n",
    "        load_graph(type='subcircuit',\n",
    "                   loader_params=loader_params)\n",
    "    subgraphs.append(sub_graph)\n",
    "    labels.append(0)\n",
    "labels[0] = 1\n",
    "\n",
    "N = len(subgraphs)\n",
    "N_training = int(2 / 3 * N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subgraphs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform graphs into S2VGraph-s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "g_list = []\n",
    "label_dict = {}\n",
    "for subgraph, label in zip(subgraphs, labels):\n",
    "    g_list.append(S2VGraph(subgraph.G, label))\n",
    "\n",
    "    if not label in label_dict:\n",
    "        mapped = len(label_dict)\n",
    "        label_dict[label] = mapped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process graph features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes: 2\n",
      "# maximum node tag: 48\n",
      "# data: 10\n"
     ]
    }
   ],
   "source": [
    "graphs, num_classes = load_data_given_graph_list_and_label_map(g_list, label_dict, degree_as_tag=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup model and training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#set up seeds and gpu device\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "##k-fold cross validation. Conduct an experiment on the fold specified by args.fold_idx.\n",
    "# train_graphs, test_graphs = separate_data(graphs, seed=0, fold_idx=0, n_splits=1)\n",
    "train_graphs = test_graphs = graphs\n",
    "\n",
    "model = GraphCNN(num_layers=5, num_mlp_layers = 2, input_dim=train_graphs[0].node_features.shape[1], hidden_dim=64, output_dim=num_classes, final_dropout=0.5, learn_eps=False, graph_pooling_type=\"sum\", neighbor_pooling_type=\"sum\", device=device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kogan\\.virtualenvs\\subcircuit_recognition-mmb-fima\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "epoch: 1: 100%|██████████| 50/50 [00:03<00:00, 15.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.255096\n",
      "accuracy train: 1.000000 test: 1.000000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2:  72%|███████▏  | 36/50 [00:01<00:00, 21.63batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17780/3846961673.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mscheduler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mavg_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miters_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_graphs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_graphs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_graphs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[0macc_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_graphs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_graphs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Desktop\\Research\\AMIT\\GraphMatching\\powerful_gnns\\classifier_training.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(iters_per_epoch, batch_size, model, device, train_graphs, optimizer, epoch)\u001B[0m\n\u001B[0;32m     28\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kogan\\.virtualenvs\\subcircuit_recognition-mmb-fima\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    253\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    254\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 255\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    256\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kogan\\.virtualenvs\\subcircuit_recognition-mmb-fima\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    145\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 147\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    148\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "filename = \"\"\n",
    "epochs = 350\n",
    "for epoch in range(1, epochs + 1):\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = train(iters_per_epoch=50, batch_size=len(train_graphs), model=model, device=device, train_graphs=train_graphs, optimizer=optimizer, epoch=epoch)\n",
    "    acc_train, acc_test = test(model, device, train_graphs, test_graphs, epoch)\n",
    "\n",
    "    if not filename == \"\":\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"%f %f %f\" % (avg_loss, acc_train, acc_test))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(model.eps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = model(train_graphs).max(1, keepdim=True)[1]\n",
    "print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}